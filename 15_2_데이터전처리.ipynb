{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2f9e4a",
   "metadata": {},
   "source": [
    "# 25.06.20(금) 오전수업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('C:/githome/3week-hipython/data/vehicle_prod.csv')\n",
    "df = pd.read_csv('./data/vehicle_prod.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03955776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.rename(columns={'Unnamed: 0':'country'})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.set_index('country', inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#국가명 컬럼으로 인덱스 설정하고 데이터프레임 생성\n",
    "df = pd.read_csv('./data/vehicle_prod.csv', index_col=0)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6024c9e",
   "metadata": {},
   "source": [
    "| 코드             | 반환 타입       | 형태  | 설명                               |\n",
    "| -------------- | ----------- | --- | -------------------------------- |\n",
    "| `df['2007']`   | `Series`    | 1차원 | 해당 컬럼만 뽑아서 \\*\\*열 벡터(1차원)\\*\\*로 추출 |\n",
    "| `df[['2007']]` | `DataFrame` | 2차원 | 하나의 열이더라도 \\*\\*표 형태(2차원)\\*\\*로 추출  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fe5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2007'] #2007 만 꺼내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['2007']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2007'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2fe93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a1b43",
   "metadata": {},
   "source": [
    "# 상관분석\n",
    "\n",
    "- 변수들간의 값의 변화의 유사도\n",
    "- 음(-)의 상관관계 : 서로 반대 방향으로 변화, 증가 > 감소, 감소 > 증가\n",
    "- 양(+)의 상관관계 : 서로 같은 방향으로 변화, 증가 > 증가, 감소 > 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 1. 숫자형 열만 골라서 상관계수 계산하기\n",
    "\n",
    "df.select_dtypes(include='number').corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c35ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "# 🛠 팁: 컬럼명 자동 복사/변환\n",
    "\n",
    "for col in df.columns:\n",
    "    print(f\"'{col}',\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac31cc",
   "metadata": {},
   "source": [
    "### 2007 ~ 2011 년까지의 생산량을 합한 total_production 컬럼을 생성해보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23428322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2007 ~ 2011 년까지의 생산량을 합한 total_production 컬럼을 생성해보자.\n",
    "\n",
    "df['total_production'] = df[['2007', '2008', '2009', '2010', '2011']].sum(axis=1)\n",
    "# axis=1은 **가로 방향(=행 기준)**으로 합산하겠다는 의미입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a015a6b",
   "metadata": {},
   "source": [
    "### total 행으로 추가 해보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92812080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total 행으로 추가 해보기\n",
    "\n",
    "# 국가별 생산량 + total_production 모두 합산한 시리즈 만들기\n",
    "total_row = df[['2007', '2008', '2009', '2010', '2011', 'total_production']].sum()\n",
    "\n",
    "# 인덱스를 'total'로 설정해 DataFrame에 행 추가\n",
    "df.loc['total'] = total_row\n",
    "# df.loc['total'] = ... 방식은 DataFrame에 새로운 행을 추가하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 생산량 합계 컬럼 추가\n",
    "df['total_production'] = df[['2007', '2008', '2009', '2010', '2011']].sum(axis=1)\n",
    "\n",
    "# 2. 총합 total 행 추가\n",
    "df.loc['total'] = df[['2007', '2008', '2009', '2010', '2011', 'total_production']].sum()\n",
    "\n",
    "# 3. 확인\n",
    "print(df.tail())  # 마지막 행(total)이 잘 추가되었는지 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시리즈 생성\n",
    "month_se = pd.Series(['1월', '2월', '3월', '4월'])\n",
    "income_se = pd.Series([9500, 6200, 6050, 7000])\n",
    "expenses_se = pd.Series([5040, 2350, 2300, 4800])\n",
    "\n",
    "# 데이터프레임 생성\n",
    "store_df = pd.DataFrame({\n",
    "    '월': month_se,\n",
    "    '수입': income_se,\n",
    "    '지출': expenses_se\n",
    "})\n",
    "\n",
    "#순수입 컬럼 추가하기\n",
    "store_df['순수입'] = store_df['수입'] - store_df['지출']\n",
    "print(store_df)\n",
    "# ✅ 1. eval() 함수 사용하기\n",
    "store_df['순수입'] = store_df.eval('수입 - 지출')\n",
    "\n",
    "\n",
    "print(store_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d34044",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#국가명 컬럼으로 인덱스 설정하고 데이터프레임 생성\n",
    "df = pd.read_csv('./data/vehicle_prod.csv', index_col=0)\n",
    "#df.rename(columns={'Unnamed: 0': 'Country'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead414c",
   "metadata": {},
   "source": [
    "### 🔹 plot.line()\n",
    "- 기본적으로 인덱스를 x축, 열(column)들을 y축으로 하는 꺾은선 그래프를 그립니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ccb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.line()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e3127c",
   "metadata": {},
   "source": [
    "### 🔹 plot.bar()\n",
    "- 각 국가(행)의 데이터를 막대그래프로 표현\n",
    "- 기본적으로 행 인덱스가 x축, **열 값들이 막대(y축)**로 나옵니다\n",
    "\n",
    "### 🔹 ax.set_xlabel(), ax.set_ylabel()\n",
    "```\n",
    "matplotlib에서 사용하는 축 레이블 설정 코드입니다.\n",
    "즉,\n",
    "x축: 국가 이름\n",
    "y축: 생산량 (단위는 데이터에 따라 다름)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.plot.bar()\n",
    "ax.set_xlabel('Country')\n",
    "ax.set_ylabel('Production')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ae5ae",
   "metadata": {},
   "source": [
    "### ✅ 1. df.transpose()\n",
    ".transpose()는 행과 열을 바꾸는 함수예요.\n",
    "\n",
    "즉, 국가명이 원래 인덱스였다면, 그게 열 이름이 되고,\n",
    "연도(2007, 2008, ...) 컬럼들이 행 인덱스가 됩니다.\n",
    "\n",
    "### ✅ 2. plot.line()\n",
    "위처럼 연도를 행 인덱스로, 국가명을 열로 바꾼 구조에서\n",
    "\n",
    ".plot.line()을 쓰면 각 국가의 연도별 생산량 추세선을 그릴 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1093e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year = df.transpose()\n",
    "df_year.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 인덱스로 바로 읽기\n",
    "df = pd.read_csv('C:/githome/3week-hipython/data/vehicle_prod.csv', index_col=0)\n",
    "\n",
    "# 2. 컬럼 확인\n",
    "print(\"인덱스 이름:\", df.index.name)\n",
    "print(\"컬럼 목록:\", df.columns.tolist())\n",
    "\n",
    "# 3. 데이터 확인\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07fbb69",
   "metadata": {},
   "source": [
    "# 결측치 np.nan, pd,NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fcf955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.nan == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2, np.nan, 4]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262aca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.NA\n",
    "pd.isna(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fc36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.NA == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aabb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a0f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'age': [25, np.nan, 30, 22, np.nan],\n",
    "    'score': [90, 85, np.nan, 88, 95],\n",
    "    'city': ['Seoul', 'Busan', np.nan, 'Incheon', 'Seoul']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78baddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 갯수 확인\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6264a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42997df9",
   "metadata": {},
   "source": [
    "# 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae519d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거\n",
    "df.dropna() # 행전체 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1) # 열전체제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f038b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['score'])  #해당컬럼의 na가 있는 행을 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c7f46",
   "metadata": {},
   "source": [
    "# 채우기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002db2b",
   "metadata": {},
   "source": [
    "# 수치형 변수의 경우는 대표값 : 평균, 중앙값, 최빈값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e5955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde341d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbe487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b04124",
   "metadata": {},
   "source": [
    "# 중앙값, 최빈값\n",
    "- median(), mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ed50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df['age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df['age'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc3b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76cb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df['age'].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#직전값ffill, 직후값 bfill\n",
    "df['score'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb218583",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'].ffill() #직전 값으로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'].bfill() #직후 값으로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a855866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age']<30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].mask(df['age']<30, 30)  #컬럼의 값에 조건을 주어, 대체할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('./data/titanic.csv')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a604c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647d939",
   "metadata": {},
   "source": [
    "### 결측치가 있는 컬럼 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b49f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치가 있는 컬럼 확인\n",
    "pd.isna(titanic_df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80681ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예: 타이타닉 데이터 불러오기\n",
    "titanic_df = pd.read_csv('./data/titanic.csv')\n",
    "\n",
    "# 1. 컬럼별 결측치 개수 확인\n",
    "print(\"#\",titanic_df.isnull().sum())\n",
    "\n",
    "# 2. 결측치가 아예 없는 컬럼은 제외하고 보기\n",
    "print(\"##2##\")\n",
    "print(titanic_df.isnull().sum()[titanic_df.isnull().sum() > 0])\n",
    "\n",
    "# 3. 결측치가 있는 컬럼만 보기 (비율 포함)\n",
    "missing_info = titanic_df.isnull().mean() * 100\n",
    "print(\"###3###\")\n",
    "print(missing_info[missing_info > 0].sort_values(ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10bbf5",
   "metadata": {},
   "source": [
    "### 📊 시각화로 보기 (선택사항)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2093c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(titanic_df.isnull(), cbar=False)\n",
    "plt.title('Missing Values in Titanic Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 1. 컬럼별 결측치 개수 확인\n",
    "# NaN(결측값)이 있는 컬럼을 확인하고, 몇 개인지 세어본다\n",
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 2. 'Age' 컬럼의 평균 나이 확인\n",
    "# 나이 결측치를 채우기 전에 평균을 확인해보자\n",
    "titanic_df['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5668c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 3. 'Age' 컬럼의 중앙값(중위수) 확인\n",
    "# 평균이 아닌 중간값도 함께 확인해보자 (이건 이상치 영향을 덜 받음)\n",
    "titanic_df['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c9e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 4. 'Age' 결측치를 중앙값으로 대체\n",
    "# 결측치를 중앙값으로 채워서 머신러닝 모델 학습에 활용할 수 있게 정리\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872065fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 5. 결측치 대체 후 데이터 상태 확인\n",
    "# 결측치가 잘 채워졌는지, 전체 데이터에 어떤 컬럼이 있고 몇 개의 데이터가 있는지 확인\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e96e76",
   "metadata": {},
   "source": [
    "### 대체후 값 검증\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 6. 결측치 대체 후 평균값 다시 확인\n",
    "# 결측치를 중앙값으로 채운 후에도 평균이 어떻게 바뀌었는지 비교해본다\n",
    "titanic_df['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1af00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 7. 나이 분포 시각화 (히스토그램)\n",
    "# 나이가 어떻게 분포되어 있는지 시각적으로 확인 (x축: 나이, y축: 사람 수)\n",
    "titanic_df['Age'].plot(kind='hist', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78533e0d",
   "metadata": {},
   "source": [
    "### cabin='unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b97ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cabin='unknown'\n",
    "titanic_df['Cabin'].fillna('Unknown', inplace=True)\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Cabin'].value_counts().head(5) #top-5 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0dfce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked 의 최빈값으로 채우기\n",
    "titanic_df['Embarked'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Embarked'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c685cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0], inplace=True)\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 원래는 선실 번호가 들어 있는 컬럼인데, 누락된 데이터가 많아서 빈칸을 'Unknown'으로 표시\n",
    "titanic_df['Cabin'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# 처리 전: 결측치 개수 확인\n",
    "print(titanic_df['Cabin'].isnull().sum())\n",
    "\n",
    "# 처리\n",
    "titanic_df['Cabin'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# 처리 후: 결측치가 사라졌는지 확인\n",
    "print(titanic_df['Cabin'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf3487",
   "metadata": {},
   "source": [
    "# 전처리 연습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/CARD_SUBWAY_MONTH_202102.csv', index_col= False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be876266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5de7fa",
   "metadata": {},
   "source": [
    "### ✅ 질문 1: len(df) 와 df.count() 는 뭐가 달라요?\n",
    "\n",
    "| 코드           | 설명                     | 출력값 의미              |\n",
    "| ------------ | ---------------------- | ------------------- |\n",
    "| `len(df)`    | **전체 행 수(총 데이터 건수)**   | NaN 포함한 **전체 행의 수** |\n",
    "| `df.count()` | **컬럼별로 NaN이 아닌 값의 개수** | 결측치가 있는 컬럼은 작게 나옴   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#총몇건인지 코드로 확인\n",
    "\n",
    "len(df)         # → 1000 (총 1000개 행)\n",
    "df.count()      # → 각 컬럼마다 결측치 제외하고 몇 건 있는지 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#평균, 표준편차, 사분위수 등 주요 통계 지표를 확인하세요\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#몇 개의 컬럼이 있는지, 각 컬럼에 포함된 데이터들의 타입은 무엇인지 확인해보세요.\n",
    "\n",
    "# 몇 개의 컬럼이 있는지 확인\n",
    "print(\"컬럼 개수:\", len(df.columns))\n",
    "\n",
    "# 각 컬럼에 포함된 데이터 타입 확인\n",
    "print(\"컬럼별 데이터 타입:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6759a",
   "metadata": {},
   "source": [
    "| 코드                | 기능              | 출력 예시                          |\n",
    "| ----------------- | --------------- | ------------------------------ |\n",
    "| `len(df.columns)` | 컬럼 수 반환         | `7` → 총 7개의 컬럼                 |\n",
    "| `df.dtypes`       | 각 컬럼의 데이터 타입 확인 | `int64`, `object`, `float64` 등 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43a19ab",
   "metadata": {},
   "source": [
    "### 📌 참고로 자주 나오는 pandas 타입들\n",
    "\n",
    "| 타입           | 의미             |\n",
    "| ------------ | -------------- |\n",
    "| `object`     | 문자열 (또는 혼합 타입) |\n",
    "| `int64`      | 정수형            |\n",
    "| `float64`    | 실수형            |\n",
    "| `datetime64` | 날짜/시간형         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb63a7",
   "metadata": {},
   "source": [
    "| 함수               | 의미                                    |\n",
    "| ---------------- | ------------------------------------- |\n",
    "| `unique()`       | 중복 없이 고유한 값들만 리스트 형태로 출력              |\n",
    "| `nunique()`      | 고유값의 **개수** 반환                        |\n",
    "| `value_counts()` | 각 값이 **몇 번 나오는지** 카운트해서 보여줌 (내림차순 정렬) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835979fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#‘노선명’ 컬럼이 가지고 있는 데이터의 종류를 확인하세요\n",
    "\n",
    "# '노선명' 컬럼에 어떤 값들이 있는지 확인 (고유값)\n",
    "print(df['노선명'].unique())\n",
    "\n",
    "# '노선명'의 고유값 개수\n",
    "print(\"노선 종류 개수:\", df['노선명'].nunique())\n",
    "\n",
    "# 각 노선별 데이터 수(빈도수) 확인\n",
    "print(df['노선명'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b4ac70",
   "metadata": {},
   "source": [
    "# ‘승차총승객수’ 컬럼을 기준으로 데이터를 정렬하세요\n",
    "\n",
    "- .sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5851a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 '승차총승객수'를 기준으로 내림차순 정렬\n",
    "df_sorted = df.sort_values(by='승차총승객수', ascending=False)\n",
    "\n",
    "# 상위 5개 행 확인\n",
    "print(df_sorted.head())\n",
    "\n",
    "# 오름차순 정렬 (작은 수부터)\n",
    "df_sorted = df.sort_values(by='승차총승객수', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#‘2호선’만 선택하세요.\n",
    "\n",
    "# '노선명'이 '2호선'인 행만 선택\n",
    "line2_df = df[df['노선명'] == '2호선']\n",
    "\n",
    "# 결과 확인\n",
    "print(line2_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘승차총승객수가’이 50000명 이상인 로우의 ‘역명’을 확인하세요.\n",
    "\n",
    "# 승차총승객수가 50,000명 이상인 행에서 '역명' 컬럼만 추출\n",
    "popular_stations = df[df['승차총승객수'] >= 50000]['역명']\n",
    "\n",
    "# 결과 확인\n",
    "print(popular_stations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a650dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘등록일자’ 컬럼을 삭제하세요\n",
    "\n",
    "# ✅ 1단계: 현재 컬럼명 확인\n",
    "print(df.columns.tolist())\n",
    "# ['사용일자', '노선명', '역명', '승차총승객수', '하차총승객수', '승하차총승객수차이']\n",
    "\n",
    "# ✅ 2단계: 공백 제거 (예방용)\n",
    "df.columns = df.columns.str.strip()  # 열 이름 앞뒤 공백 제거\n",
    "\n",
    "# ✅ 3단계: 다시 컬럼 삭제 시도\n",
    "# '등록일자' 컬럼을 삭제 (원본 df에 바로 반영)\n",
    "if '등록일자' in df.columns:\n",
    "    df.drop(columns='등록일자', inplace=True)\n",
    "\n",
    "\n",
    "# 결과 확인\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'승차총승객수’와 ‘하차총승객수’ 컬럼의 차이를 계산한 ‘승하차총승객수차이’ 컬럼을 생성하세요.\n",
    "\n",
    "# 승차총승객수와 하차총승객수의 차이 계산해서 새로운 컬럼 생성\n",
    "df['승하차총승객수차이'] = abs(df['승차총승객수'] - df['하차총승객수'])\n",
    "\n",
    "# 결과 확인\n",
    "print(df[['노선명', '역명', '승차총승객수', '하차총승객수', '승하차총승객수차이']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454aaf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '승하차총승객수차이' 컬럼의 평균값 계산\n",
    "mean_value = df['승하차총승객수차이'].mean()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"승하차총승객수차이의 평균값:\", mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d753e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 중 10개의 아이템을 샘플링해서 데이터프레임을 생성하세요.\n",
    "#.sample()\n",
    "sample_df = []\n",
    "# 이건 빈 리스트(empty list) 를 만드는 코드입니다.\n",
    "# 아무 데이터도 없고, pandas와는 관련 없는 Python 기본 리스트 타입\n",
    "#  데이터프레임이 아니라서 .head() 같은 pandas 함수 사용 불가\n",
    "print(type(sample_df))  # <class 'list'>\n",
    "\n",
    "# 전체 데이터 중에서 무작위로 10개 행 샘플링\n",
    "sample_df = df.sample(n=10, random_state=42)  # random_state는 결과 재현용\n",
    "# 전체의 10% 샘플링 비율로 추출하고싶을 때 활용\n",
    "# df.sample(frac=0.1)  \n",
    "\n",
    "# 결과 확인\n",
    "print(sample_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_df의 ‘노선명’ 컬럼의 값이 1호선, 2호선, 3호선 4호선을 영어(line1, line2, line3, line4)로 변경하세요\n",
    "\n",
    "# 한글 노선명을 영어로 바꿀 매핑 딕셔너리 생성\n",
    "line_mapping = {\n",
    "    '1호선': 'line1',\n",
    "    '2호선': 'line2',\n",
    "    '3호선': 'line3',\n",
    "    '4호선': 'line4'\n",
    "}\n",
    "\n",
    "# sample_df의 '노선명' 컬럼에 매핑 적용\n",
    "sample_df['노선명'] = sample_df['노선명'].map(line_mapping).fillna(sample_df['노선명'])\n",
    "\n",
    "# 결과 확인\n",
    "print(sample_df[['노선명', '역명']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8babcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 '사용일자'로 바꾸어 설정해보기\n",
    "\n",
    "# '사용일자' 컬럼을 인덱스로 설정\n",
    "df.set_index('사용일자', inplace=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(df.head())\n",
    "print(df.index.name)  # 인덱스가 잘 설정됐는지 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6277c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '사용일자' 컬럼을 연도-월-일(예:2021-02-01)의 형태로 표시되도록 수정하세요.\n",
    "# UDF 정의 getData(data)\n",
    "\n",
    "def getDate(data):\n",
    "    dt = str(data)\n",
    "    yy = dt[0:4]\n",
    "    mm = dt[4:6]\n",
    "    dd = dt[6:8]\n",
    "    return yy+'-'+mm+'-'+dd\n",
    "\n",
    "d='20210303'\n",
    "getDate(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a603c193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사용일자', '노선명', '역명', '승차총승객수', '하차총승객수', '등록일자']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"중앙선--\" doesn't match format \"%Y-%m-%d\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[204]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m yy + \u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m + mm + \u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m + dd\n\u001b[32m     15\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33m사용일자\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33m사용일자\u001b[39m\u001b[33m'\u001b[39m].apply(getDate)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33m사용일자\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33m사용일자\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1068\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1066\u001b[39m             result = arg.tz_localize(\u001b[33m\"\u001b[39m\u001b[33mutc\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m     cache_array = _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array.empty:\n\u001b[32m   1070\u001b[39m         result = arg.map(cache_array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:249\u001b[39m, in \u001b[36m_maybe_cache\u001b[39m\u001b[34m(arg, format, cache, convert_listlike)\u001b[39m\n\u001b[32m    247\u001b[39m unique_dates = unique(arg)\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) < \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     cache_dates = convert_listlike(unique_dates, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[32m    437\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    438\u001b[39m     arg,\n\u001b[32m    439\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    444\u001b[39m )\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    447\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:469\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    459\u001b[39m     arg,\n\u001b[32m    460\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    465\u001b[39m ) -> Index:\n\u001b[32m    466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     result, tz_out = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    471\u001b[39m         unit = np.datetime_data(result.dtype)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:501\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:451\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:583\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime._parse_with_format\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: time data \"중앙선--\" doesn't match format \"%Y-%m-%d\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/CARD_SUBWAY_MONTH_202102.csv')\n",
    "\n",
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "def getDate(data):\n",
    "    dt = str(data)\n",
    "    yy = dt[0:4]\n",
    "    mm = dt[4:6]\n",
    "    dd = dt[6:8]\n",
    "    return yy + '-' + mm + '-' + dd\n",
    "\n",
    "df['사용일자'] = df['사용일자'].apply(getDate)\n",
    "df['사용일자'] = pd.to_datetime(df['사용일자'], format='%Y-%m-%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c1e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a574f12f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
